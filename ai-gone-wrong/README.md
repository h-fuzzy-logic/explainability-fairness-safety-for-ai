# Cases of AI Systems Failing to Perform as Expected

## Amazon's resume screening tool 
Amazon decided to stop working on its resume screening tool because it showed bias against women. Resumes were scored lower if they contained phrases like "women's chess club‚Äù or included graduation from an all-women college.
Source: [Reuters](https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/)

## Dogs vs. wolves image classification project 
Images of animals were incorrectly classified. Images containing snow in the background were more likely to be classified as a wolf. So images of huskies with snow in the background were incorrectly classified as wolves.  
Source: [ResearchGate](https://www.researchgate.net/figure/A-husky-on-the-left-is-confused-with-a-wolf-because-the-pixels-on-the-right_fig1_329277474) 

## Airline chatbot gives wrong price for bereavement ticket
An airline chatbot gave false information about discounts for last-minute travel for a funeral, causing a larger-than-expected expense for a grieving gentleman.  
Source: [Mashable](https://mashable.com/article/air-canada-forced-to-refund-after-chatbot-misinformation) 

